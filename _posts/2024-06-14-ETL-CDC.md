---
layout: post
title: ETL, CDC 비교 및 이해
subtitle: ETL과 CDC
tags: [ETL, CDC, oracle,postgres,mysql]
---

## ETL (Extract, Transform, Load)

#### 설명
- **Extract (추출)**: 소스 시스템에서 데이터를 추출합니다. 소스 시스템은 RDBS, FS(파일 시스템), 클라우드 저장소 등 다양한 형태일 수 있습니다.
- **Transform (변환)**: 추출된 데이터를 변환하여 타겟 시스템에 적합한 형식으로 만듭니다. 이 과정에서는 데이터 정제, 집계, 필터링, 데이터 타입 변환, 데이터 변조(가명화를 위하여) 등의 작업이 포함됩니다.
- **Load (적재)**: 변환된 데이터를 목표 시스템(주로 DW/데이터 웨어하우스나 DM/데이터 마트), 타겟 테이블에 적재합니다.

#### 주요 특징
- **Schema Alignment**: 소스 테이블과 타겟 테이블 간의 스키마(레이아웃)가 일치 해야 되지만, 타겟 테이블은 소스 테이블보다 더 많은 컬럼을 가질 수 있습니다. 타겟 테이블의 추가 컬럼은 Nullable하거나 설정할 수 있습니다.
- **Batch Processing**: 주로 배치 처리 방식으로 대량의 데이터를 주기적으로 처리합니다.
- **데이터 품질 보장**: 변환 단계에서 데이터 정제와 통합이 이루어져 데이터 품질을 보장합니다.

#### 사용 방법
- **Oracle 데이터베이스**: Oracle에서 ETL 도구로 [Oracle SQL*Loader](https://docs.oracle.com/en/database/oracle/oracle-database/19/sutil/oracle-sql-loader.html#GUID-8D037494-07FA-4226-B507-E1B2ED10C144)를 사용하여 대량의 데이터를 효율적으로 적재할 수 있습니다.
- **MySQL** & **MariaDB**: MySQL에서는 [`LOAD DATA INFILE`](https://dev.mysql.com/doc/refman/8.4/en/load-data.html) 명령어를 사용, MariaDB에서도 [`LOAD DATA INFILE`](https://mariadb.com/kb/en/load-data-infile/) 명령어를 사용하여 대량 데이터를 적재할 수 있습니다.
- **PostgreSQL**: PostgreSQL에서는 [`COPY`](https://www.postgresql.org/docs/current/sql-copy.html) 명령어를 사용하여 대량 데이터를 빠르게 적재할 수 있습니다.
- **ETL 도구**: 일반적으로 ETL 도구로는 [TerraStream](https://datastreams.co.kr/products/data-integration-terastream/), [Informatica](https://www.informatica.com/kr/), [PDI(Pentaho Data Integration)](https://pentaho.com/products/pentaho-data-integration/), Talend, Apache Nifi가 사용됩니다.
또한 [AWS Glue](https://docs.aws.amazon.com/ko_kr/glue/latest/dg/what-is-glue.html) 라는 클라우드 기반 ETL Tool도 있습니다.

#### 적재 방법
- **Truncate and Load**: 기존 데이터를 삭제(truncate)하고 새로운 데이터를 적재합니다. 데이터 일관성을 유지하기 쉽지만, 적재 중에 데이터가 비어 있을 수 있습니다. truncate를 통해 index rebulid 처리까지 적용된 효과를 기대할 수 있습니다.
- **Append**: 기존 데이터에 새로운 데이터를 추가합니다. 데이터 중복을 피하기 위한 고유 키를 관리해야 합니다.
- **Incremental Load**: 변경된 데이터만 적재합니다. 주로 타임스탬프나 고유 식별자를 사용하여 변경된 레코드를 식별합니다.

## CDC (Change Data Capture)

#### 설명
- 소스 시스템에서 데이터 변경 사항을 캡처하여  다른 시스템에 적용합니다.

#### 주요 특징
- **Real-Time Processing**: CDC는 실시간으로 데이터 변경 사항을 캡처하고 전송할 수 있습니다.
- **Incremental Updates**: 전체 데이터를 다시 적재하지 않고, 변경된 데이터만 캡처하여 전송합니다.
- **Event-Driven**: 데이터 변경 이벤트에 따라 동작하므로, 실시간 동기화와 같은 애플리케이션에 적합합니다.
- **Log-Based Capture**: 주로 데이터베이스의 트랜잭션 로그를 기반으로 변경 사항을 추적합니다.

#### 목적
- **데이터 동기화**: 서로 다른 시스템 간의 데이터 일관성을 유지합니다.
- **실시간 분석**: 변경 사항을 실시간으로 분석 시스템에 반영하여 실시간 분석을 가능하게 합니다.

#### 유사점
- **데이터 통합**: ETL과 CDC 모두 데이터 통합을 목적으로 합니다.
- **데이터 이동**: 둘 다 소스 시스템에서 타겟 시스템으로 데이터를 이동시킵니다.

#### 차이점
- **처리 방식**: ETL은 배치 처리 방식이고, CDC는 실시간 처리 방식입니다.
- **데이터 볼륨**: ETL은 전체 데이터를 주기적으로 처리하는 반면, CDC는 변경된 데이터만 처리합니다.
- **변환 단계**: ETL은 변환 단계가 필수지만, CDC는 주로 변경 사항만 캡처하므로 변환 단계가 간단하거나 생략될 수 있습니다.

#### 사용 방법
- **Log-Based CDC**: 데이터베이스 트랜잭션 로그를 분석하여 변경 사항을 캡처하는 방법입니다. Oracle의 [GoldenGate(OGG)](https://www.oracle.com/kr/integration/goldengate/), MySQL의 Debezium, PostgreSQL의 logical replication 등이 이 방식을 사용합니다.
- **Trigger-Based CDC**: 데이터베이스 트리거를 사용하여 변경 사항을 캡처하는 방법입니다.
- **Timestamp-Based CDC**: 레코드의 타임스탬프를 사용하여 변경된 레코드를 식별하는 방법입니다.

### 적용 사례
- **ETL**: 데이터 웨어하우스 구축, 주기적인 데이터 마이그레이션, 대량 데이터 처리 등이 포함됩니다.
- **CDC**: 실시간 데이터 동기화, 실시간 분석, 데이터 스트리밍 애플리케이션 등에 사용됩니다.

### 현황
금융회사는 보통 높은 비중의 Oracle Database, Tibero Database(티맥스)가 사용중입니다. 금융회사의 데이터는 고객에 대한 정보이기 떄문에 높은 warranty가 필요하기 때문입니다. 그렇기에 상용소프트웨어(테라스트림, 인포메티카, OGG)로 ETL, CDC 작업을 수행중입니다. 최근 U2L 일환으로 mysql&mariadb, postgresql로 전환 또는 사용 추세입니다.<br><br>
각 사이트, 프로젝트, 비지니스 상황에 맞게 ETL, CDC 방식으로 데이터 처리를 할 수 있고, 각각의 기술별 조건들을 활용하여 필요에 맞는 데이터 처리를 진행 할 수 있습니다.